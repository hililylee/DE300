{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0674605d-55fc-4390-8806-57beaf51dc4c",
   "metadata": {},
   "source": [
    "# Loading required packages #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2fd67479-8246-44c4-8fdf-a24996c11e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#required for reading .xml files\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "\n",
    "#required for navigating machine's directory\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "#required for communicating with SQL database\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b5b06d1-8024-4275-a5cb-d0814ce92e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the postgresql address for SQL base coonection\n",
    "conn_string = 'postgresql://admin:de300SPRING2024@dd300spring2024.549787090008.us-east-2.redshift-serverless.amazonaws.com:5439/dev'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff313c-6512-4bac-9f53-715905a27ff3",
   "metadata": {},
   "source": [
    "## Utility function for writing data into the SQL database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a657987c-2f48-4ef3-90a3-5d006085c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_to_table(data: pd.DataFrame, table_name:str):\n",
    "    db = create_engine(conn_string)\n",
    "    conn = db.connect()\n",
    "    data.to_sql(table_name, conn, if_exists=\"replace\", index=False)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5bc98-65b6-49fe-8c6e-4ec611c84a5d",
   "metadata": {},
   "source": [
    "## Step one : Extract data from ./data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "347e2764-7f50-46cd-8057-ef714371b04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/used_car_prices2.xml\n",
      "./data/used_car_prices3.json\n",
      "./data/used_car_prices2.csv\n",
      "./data/used_car_prices3.xml\n",
      "./data/used_car_prices1.xml\n",
      "./data/used_car_prices2.json\n",
      "./data/used_car_prices3.csv\n",
      "./data/used_car_prices1.json\n",
      "./data/used_car_prices1.csv\n"
     ]
    }
   ],
   "source": [
    "all_files = glob.glob('./data/*')\n",
    "\n",
    "# Output the list of files\n",
    "for file in all_files:\n",
    "    print(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac0651-0a3a-4a4a-8fd7-31ac586022a1",
   "metadata": {},
   "source": [
    "## Function to extract data from one .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "da9535e2-9526-4dd6-9d61-edcf817e6b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process: str) -> pd.DataFrame:\n",
    "    # add you line here to read the .csv file and return dataframe\n",
    "    df = pd.read_csv(file_to_process)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a39f5-75b3-4091-bfc8-2688ca99a4a0",
   "metadata": {},
   "source": [
    "## Function to extract data from one .json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82618a1d-f895-4896-8d2c-def63f4f98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process: str) -> pd.DataFrame:\n",
    "    \n",
    "    # add you line here to read the .json file and return dataframe\n",
    "    df = pd.read_json(file_to_process,lines=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a26b2a3-322f-4320-974f-f29faed00db9",
   "metadata": {},
   "source": [
    "## Function to extract data from one .xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e982025-2082-436d-bdb1-818f50fc2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process: str) -> pd.DataFrame:\n",
    "    dataframe = pd.DataFrame(columns = columns)\n",
    "    tree = ET.parse(file_to_process)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        car_model = person.find(\"car_model\").text\n",
    "        year_of_manufacture = int(person.find(\"year_of_manufacture\").text)\n",
    "        price = float(person.find(\"price\").text)\n",
    "        fuel = person.find(\"fuel\").text\n",
    "        sample = pd.DataFrame({\"car_model\":car_model, \"year_of_manufacture\":year_of_manufacture, \"price\":price, \"fuel\":fuel}, index = [0])\n",
    "        dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6149b7a-5a9b-4476-948d-ffcfa8c3f81a",
   "metadata": {},
   "source": [
    "## Function to extract data from the ./data/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ef3c2fd8-d5d4-4816-984f-d32385211a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract() -> pd.DataFrame:\n",
    "    extracted_data = pd.DataFrame(columns = columns)\n",
    "    #for csv files\n",
    "    for csv_file in glob.glob(os.path.join(folder, \"*.csv\")):\n",
    "        extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
    "    \n",
    "   # For JSON files\n",
    "    for json_file in glob.glob(os.path.join(folder, \"*.json\")):\n",
    "       extracted_data = pd.concat([extracted_data, extract_from_json(json_file)], ignore_index=True)\n",
    "         \n",
    "    # For XML files\n",
    "    for xml_file in glob.glob(os.path.join(folder, \"*.xml\")):\n",
    "        xml_data = extract_from_xml(xml_file)\n",
    "        extracted_data = pd.concat([extracted_data, xml_data], ignore_index=True)\n",
    "    \n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b35ad-f8ea-43af-8a6f-8db836751854",
   "metadata": {},
   "source": [
    "## Extract the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e240c6e9-60ee-42e4-b918-05e1cd1955e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_349/2081731269.py:5: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, extract_from_csv(csv_file)], ignore_index=True)\n",
      "/tmp/ipykernel_349/3387287639.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_349/3387287639.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n",
      "/tmp/ipykernel_349/3387287639.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataframe = pd.concat([dataframe, sample], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "columns = ['car_model','year_of_manufacture','price', 'fuel']\n",
    "folder = \"data\"\n",
    "#table_name = \"car_data\"\n",
    "\n",
    "# run\n",
    "def main():\n",
    "    data = extract()\n",
    "    #insert_to_table(data, \"car_data\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1e86d1-e7a8-47c8-82db-f21fdf0bb793",
   "metadata": {},
   "source": [
    "## Step Two: Transformation of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4eb50c4-c13b-4522-9bd3-793e81d0faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "staging_file = \"cars.parquet\"\n",
    "staging_data_dir = \"staging_data\"\n",
    "\n",
    "def transform(df):\n",
    "    #db = create_engine(conn_string)\n",
    "\n",
    "    #df = pd.read_sql_query(f'SELECT * FROM {table_name}',con=db)\n",
    "\n",
    "    print(f\"Shape of data {df.shape}\")\n",
    "\n",
    "    # truncate price with 2 decimal place (add your code below)\n",
    "    df['price'] = df['price'].round(2)\n",
    "\n",
    "    # remove samples with same car_model (add your code below)\n",
    "    df = df.drop_duplicates(subset='car_model', keep='first')\n",
    "    \n",
    "    print(f\"Shape of data {df.shape}\")\n",
    "\n",
    "    if not os.path.exists(staging_data_dir):\n",
    "        os.makedirs(staging_data_dir)\n",
    "\n",
    "    # write to parquet\n",
    "    df.to_parquet(os.path.join(staging_data_dir, staging_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d70e846-9d33-46a6-9153-c27f5aec75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car_model year_of_manufacture         price    fuel\n",
      "0  alto 800                2017   4253.731343  Petrol\n",
      "1      ciaz                2015  10223.880597  Diesel\n",
      "2      ciaz                2015  11194.029851  Petrol\n",
      "3    ertiga                2015   9104.477612  Petrol\n",
      "4     dzire                2009   3358.208955  Petrol\n"
     ]
    }
   ],
   "source": [
    "# print the head of your data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "02ae105c-5e20-4e97-b62e-f98a792ccd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  car_model year_of_manufacture     price    fuel\n",
      "0  alto 800                2017   4253.73  Petrol\n",
      "1      ciaz                2015  10223.88  Diesel\n",
      "3    ertiga                2015   9104.48  Petrol\n",
      "4     dzire                2009   3358.21  Petrol\n",
      "8   wagon r                2015   4850.75     CNG\n"
     ]
    }
   ],
   "source": [
    "def transform2(df):\n",
    "# truncate price with 2 decimal place (add your code below)\n",
    "    df['price'] = df['price'].round(2)\n",
    "\n",
    "    # remove samples with same car_model (add your code below)\n",
    "    df = df.drop_duplicates(subset='car_model', keep='first')\n",
    "    return df\n",
    "    \n",
    "# Print the head of the data\n",
    "print(transform2(data).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c9da1e-49ba-4531-808b-0f3d10d89886",
   "metadata": {},
   "source": [
    "## Step Three : Loading data for further modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a1862af8-5c83-4b98-8387-15656ed165c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 4)\n"
     ]
    }
   ],
   "source": [
    "# read from the .parquet file\n",
    "\n",
    "def load() -> pd.DataFrame:\n",
    "    data = pd.DataFrame()\n",
    "    for parquet_file in glob.glob(os.path.join(staging_data_dir, \"*.parquet\")):\n",
    "        data = pd.concat([pd.read_parquet(parquet_file),data])\n",
    "\n",
    "    #insert_to_table(data, table_name)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = load()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b35fc-943b-46e9-8d84-62522b7d3174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
